actor_rollout_ref:
  model:
    path: /dnn_training_sys/users/hanxudong.hxd/OpenRLHF/Llama-3-8b-sft-mixture
    enable_gradient_checkpointing: True
  strategy: deepspeed  # This is for backward-compatibility
  rollout_batch_size: 128
  mini_batch_size: 8192 # total batch_size 128*64
  micro_batch_size: 8 # pack的大小
  micro_train_batch_size: 16 # train micro
  init_kl_coef: 0
  actor:
    optim:
      lr: 1e-6
      betas: [0.9, 0.95]
      weight_decay: 0.01
      total_training_steps: 1000
    deepspeed_config:
      dtype: bf16
      offload: True
      zero_stage: 3
      clip_grad: 1.0
  ref:
    deepspeed_config:
      dtype: bf16
      offload: True
      zero_stage: 3
  rollout:
    type: vllm # huggingface
    tp_size: 1
    gpu_memory_utilization: 0.4
    sample_params:
      # do_sample: True # 实际没用到
      temperature: 1
      top_p: 1.0
      top_k: -1
      n_samples_per_prompt: 64
reward:
  model:
    path: /root/Llama-3-8b-rm-mixture2
  strategy: deepspeed  # This is for backward-compatibility
  mini_batch_size: 8192 # total batch_size 
  micro_batch_size: 8 # 已经pack
  deepspeed_config:
    dtype: bf16
    offload: True
    zero_stage: 3
critic:
  model:
    path: /root/Llama-3-8b-rm-mixture2
    enable_gradient_checkpointing: True
  strategy: deepspeed  # This is for backward-compatibility
  mini_batch_size: 8192 # total batch_size 128*64
  micro_batch_size: 8 # 已经pack
  micro_train_batch_size: 16 # train micro
  optim:
    lr: 5e-6
    betas: [0.9, 0.95]
    weight_decay: 0.01
    total_training_steps: 1000

  deepspeed_config:
    dtype: bf16
    offload: True
    zero_stage: 3
    clip_grad: 1.0

trainer:
  n_gpus_per_node: 8
  nnodes: 4
  total_epochs: 1
  project_dir: ./test
  checkpoint_steps: 2000
  exp_name: test
  rl_train_batch_size: 5
  rollout_size: 1
  batches_per_rollout: 10
  num_train_epochs: 1
  rl_train_epochs: 1
  gradient_checkpointing: true
  seed: 42
  ac_mode: non_share
  enable_ref: true

placement:
  strategy: interleaving

data:
  prompt_data_path: /dnn_training_sys/users/hanxudong.hxd/prompt-collection-v0.1/data
  prompt_template: /input/jiulin.jl/code/orz_base_template
  num_total_iters: 1